# íŒŒì¼ëª…: app.py
import os
import re
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import numpy as np
import pickle
from konlpy.tag import Okt
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
import glob

# --- ì•± ê¸°ë³¸ ì„¤ì • (ê°€ì¥ ë¨¼ì € ì‹¤í–‰) ---
st.set_page_config(layout="wide", page_title="ë©”ì´í”Œ ì—¬ë¡  ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

# --- ê²½ë¡œ ì„¤ì • ---
BASE_DIR = os.getcwd()
MODEL_ROOT_DIR = os.path.join(BASE_DIR, 'production_models')
LABELED_CHUNK_DIR = os.path.join(BASE_DIR, 'data', 'labeled_chunks')
STOPWORDS_PATH = os.path.join(BASE_DIR, 'data', 'korean_stopwords.txt')
# â˜… ì‚¬ìš©ì í”¼ë“œë°± ì €ì¥ ê²½ë¡œ ì¶”ê°€
FEEDBACK_FILE_PATH = os.path.join(BASE_DIR, 'data', 'user_feedback.csv')
FONT_PATH = "C:/Windows/Fonts/malgun.ttf"
MAX_LEN = 60

# --- ë°ì´í„° ë° ëª¨ë¸ ë¡œë”© (ìºì‹± ê¸°ëŠ¥ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”) ---
@st.cache_resource
def load_prediction_assets():
    """ì‹¤ì‹œê°„ ì˜ˆì¸¡ì— í•„ìš”í•œ ìµœì‹  ë²„ì „ì˜ ëª¨ë¸, í† í¬ë‚˜ì´ì €, Okt, ë¶ˆìš©ì–´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    # ... (ì´ì „ê³¼ ë™ì¼)
    if not os.path.exists(MODEL_ROOT_DIR): return None, None, None, [], "ëª¨ë¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤."
    version_dirs = glob.glob(os.path.join(MODEL_ROOT_DIR, 'v_*'))
    if not version_dirs: return None, None, None, [], "í•™ìŠµëœ ëª¨ë¸ ë²„ì „ì´ ì—†ìŠµë‹ˆë‹¤."
    latest_version_dir = max(version_dirs, key=os.path.getctime)
    model_path = os.path.join(latest_version_dir, 'model.h5')
    tokenizer_path = os.path.join(latest_version_dir, 'tokenizer.pkl')
    try:
        _model = load_model(model_path)
        with open(tokenizer_path, 'rb') as f: _tokenizer = pickle.load(f)
        with open(STOPWORDS_PATH, 'r', encoding='utf-8') as f: _stopwords = [line.strip() for line in f]
        _okt = Okt()
        return _model, _tokenizer, _okt, _stopwords, f"ìµœì‹  ëª¨ë¸ '{os.path.basename(latest_version_dir)}' ë¡œë“œ ì™„ë£Œ."
    except Exception as e:
        return None, None, None, [], f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}"

@st.cache_data
def load_dashboard_data():
    """
    ëŒ€ì‹œë³´ë“œ ì‹œê°í™”ì— ì‚¬ìš©í•  ê°€ì¥ ìµœì‹  ë¼ë²¨ë§ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
    â˜… ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.
    """
    st.subheader("ğŸ•µï¸â€â™‚ï¸ ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë¡œë”© ê³¼ì • ì§„ë‹¨")
    
    if not os.path.exists(LABELED_CHUNK_DIR):
        return pd.DataFrame(), f"ì˜¤ë¥˜: ë¼ë²¨ë§ëœ ë°ì´í„° í´ë” '{LABELED_CHUNK_DIR}'ê°€ ì—†ìŠµë‹ˆë‹¤."

    labeled_files = glob.glob(os.path.join(LABELED_CHUNK_DIR, 'labeled_data_*.csv'))
    if not labeled_files:
        return pd.DataFrame(), f"ì˜¤ë¥˜: '{LABELED_CHUNK_DIR}' í´ë”ì— ë¼ë²¨ë§ëœ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."

    latest_data_path = max(labeled_files, key=os.path.getctime)
    st.info(f"1. ìµœì‹  ë°ì´í„° íŒŒì¼ í™•ì¸: '{os.path.basename(latest_data_path)}'")
    
    try:
        df = pd.read_csv(latest_data_path, encoding='utf-8-sig')
        st.info(f"2. íŒŒì¼ ë¡œë“œ ì„±ê³µ: ì´ {len(df)}ê°œì˜ í–‰ì„ ì½ì—ˆìŠµë‹ˆë‹¤.")
        st.write("3. ì›ë³¸ ë°ì´í„° ì»¬ëŸ¼ ëª©ë¡:", df.columns.tolist())

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_cols = ['ì œëª©', 'ë³¸ë¬¸', 'label']
        if not all(col in df.columns for col in required_cols):
             return pd.DataFrame(), f"ì˜¤ë¥˜: íŒŒì¼ì— í•„ìˆ˜ ì»¬ëŸ¼({required_cols}) ì¤‘ ì¼ë¶€ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ì „ì²˜ë¦¬
        df.dropna(subset=['label'], inplace=True)
        st.info(f"4. 'label'ì´ ì—†ëŠ” í–‰ ì œê±° í›„: {len(df)}ê°œ í–‰ ë‚¨ìŒ")

        df['cleaned_text'] = (df['ì œëª©'].fillna('') + ' ' + df['ë³¸ë¬¸'].fillna('')).apply(lambda x: re.sub(r"[^ê°€-í£0-9a-zA-Z\s]", " ", str(x)))
        df['job'] = df['ì œëª©'].str.extract(r'^\[(.*?)\]').fillna('ê¸°íƒ€')
        df['sentiment_name'] = df['label'].map({0.0: 'ë¶€ì •', 1.0: 'ì¤‘ë¦½', 2.0: 'ê¸ì •'}) # labelì´ floatì¼ ê²½ìš° ëŒ€ë¹„
        
        st.success("5. ì „ì²˜ë¦¬ ì™„ë£Œ. ëŒ€ì‹œë³´ë“œë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
        return df, f"ìµœì‹  ë°ì´í„° '{os.path.basename(latest_data_path)}' ë¡œë“œ ì™„ë£Œ."
    except Exception as e:
        return pd.DataFrame(), f"ì˜¤ë¥˜: ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ - {e}"

# --- ì•± ì‹¤í–‰ ë° UI êµ¬ì„± ---
st.title("ğŸ ë©”ì´í”ŒìŠ¤í† ë¦¬ ì§ì—…ë³„ ì—¬ë¡  ëŒ€ì‹œë³´ë“œ & ì‹¤ì‹œê°„ ê°ì„± ë¶„ì„")

# ë°ì´í„° ë° ëª¨ë¸ ë¡œë“œ
df, dashboard_msg = load_dashboard_data()
model, tokenizer, okt, stopwords, model_msg = load_prediction_assets()

# íƒ­ ìƒì„±
tab1, tab2 = st.tabs(["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ¤– ì‹¤ì‹œê°„ ê°ì„± ë¶„ì„"])

with tab1:
    st.info(dashboard_msg)
    if df.empty:
        # ì´ ë©”ì‹œì§€ê°€ ë³´ì¸ë‹¤ë©´, load_dashboard_data í•¨ìˆ˜ê°€ ë¹ˆ ë°ì´í„°í”„ë ˆì„ì„ ë°˜í™˜í•œ ê²ƒ
        st.error("ëŒ€ì‹œë³´ë“œì— í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ ì§„ë‹¨ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        # (ì´í•˜ ëŒ€ì‹œë³´ë“œ UI ë¡œì§ì€ ì´ì „ê³¼ ê±°ì˜ ë™ì¼)
        col1, col2 = st.columns([1, 3])
        with col1:
            st.header("ğŸ” í•„í„°")
            boards = ['ì „ì²´'] + sorted(df['ê²Œì‹œíŒ'].unique().tolist())
            sel_board = st.selectbox("ê²Œì‹œíŒ ì„ íƒ", boards, key='board_select')
            if sel_board == 'ì „ì²´':
                jobs = sorted(df['job'].unique().tolist())
            else:
                jobs = sorted(df[df['ê²Œì‹œíŒ'] == sel_board]['job'].unique().tolist())
            sel_jobs = st.multiselect("ì§ì—… ì„ íƒ", jobs, default=jobs, key='job_multiselect')
        with col2:
            if sel_jobs:
                df_filtered = df[df['job'].isin(sel_jobs)]
                st.write(f"ì´ **{len(df_filtered)}** ê±´ì˜ ê²Œì‹œê¸€ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
                st.subheader("ê°ì„± ë¶„í¬")
                # 'sentiment_name' ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ëŒ€ë¹„
                if 'sentiment_name' in df_filtered.columns:
                    ratio = df_filtered['sentiment_name'].value_counts(normalize=True).reindex(['ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •'], fill_value=0)
                    st.bar_chart(ratio)
                else:
                    st.warning("'sentiment_name' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                st.subheader("ì£¼ìš” í‚¤ì›Œë“œ (ì›Œë“œí´ë¼ìš°ë“œ)")
                text = " ".join(df_filtered['cleaned_text'].dropna().tolist())
                if text:
                    try:
                        wc = WordCloud(font_path=FONT_PATH, width=800, height=400, background_color='white', stopwords=set(stopwords)).generate(text)
                        fig, ax = plt.subplots(figsize=(12, 6))
                        ax.imshow(wc, interpolation='bilinear')
                        ax.axis('off')
                        st.pyplot(fig)
                    except Exception as e:
                        st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            else:
                st.warning("ë¶„ì„í•  ì§ì—…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

with tab2:
    st.info(model_msg)
    st.header("ì‹¤ì‹œê°„ ê°ì„± ë¶„ì„ê¸°")
    if model and tokenizer:
        user_input = st.text_area("ë¶„ì„í•  ë¬¸ì¥ì„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”:", height=150, key="user_input")
        if st.button("ë¶„ì„ ì‹¤í–‰", key="predict_button"):
            if user_input.strip():
                with st.spinner('ëª¨ë¸ì´ ê°ì„±ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                    # ëª¨ë¸ ì˜ˆì¸¡ ë¡œì§
                    tokenized = [word for word in okt.morphs(user_input, stem=True) if word not in stopwords]
                    encoded = tokenizer.texts_to_sequences([tokenized])
                    padded = pad_sequences(encoded, maxlen=MAX_LEN)
                    score = model.predict(padded)
                    pred_class = np.argmax(score, axis=1)[0]
                    # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (í”¼ë“œë°± ì €ì¥ì„ ìœ„í•´)
                    st.session_state['last_input'] = user_input
                    st.session_state['pred_class'] = pred_class
                    st.session_state['score'] = score
            else:
                st.warning("ë¶„ì„í•  ë¬¸ì¥ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        # ì„¸ì…˜ ìƒíƒœì— ë¶„ì„ ê²°ê³¼ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ê²°ê³¼ ë° í”¼ë“œë°± UI í‘œì‹œ
        if 'last_input' in st.session_state:
            pred_class = st.session_state['pred_class']
            score = st.session_state['score']
            confidence = score[0][pred_class] * 100
            
            st.subheader("âœ¨ ë¶„ì„ ê²°ê³¼")
            if pred_class == 2: st.success(f"**ê¸ì •ì ì¸ ì˜ê²¬**ì¼ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ({confidence:.2f}%)")
            elif pred_class == 1: st.warning(f"**ì¤‘ë¦½ì ì¸ ì˜ê²¬**ì¼ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ({confidence:.2f}%)")
            else: st.error(f"**ë¶€ì •ì ì¸ ì˜ê²¬**ì¼ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ({confidence:.2f}%)")
            
            st.bar_chart({'ê¸ì •': score[0][2], 'ì¤‘ë¦½': score[0][1], 'ë¶€ì •': score[0][0]})
            
            # â˜… ì‚¬ìš©ì í”¼ë“œë°± UI ë¶€ë¶„ â˜…
            st.write("---")
            st.subheader("âœï¸ ëª¨ë¸ì˜ íŒë‹¨ì´ ì •í™•í•œê°€ìš”? í”¼ë“œë°±ì„ ë‚¨ê²¨ì£¼ì„¸ìš”.")
            
            with st.form(key='feedback_form'):
                sentiment_options = ['ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •']
                # ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
                default_index = {2: 0, 1: 1, 0: 2}.get(pred_class, 1) # ê¸ì •(2)->0, ì¤‘ë¦½(1)->1, ë¶€ì •(0)->2
                
                user_label_text = st.radio(
                    label="ì´ ë¬¸ì¥ì˜ ì‹¤ì œ ê°ì„±ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                    options=sentiment_options,
                    index=default_index,
                    horizontal=True
                )
                submitted = st.form_submit_button("í”¼ë“œë°± ì €ì¥í•˜ê¸°")
                
                if submitted:
                    label_map_to_int = {'ê¸ì •': 2, 'ì¤‘ë¦½': 1, 'ë¶€ì •': 0}
                    final_label = label_map_to_int[user_label_text]
                    text_to_save = st.session_state['last_input']
                    
                    if save_feedback(text_to_save, final_label):
                        st.success("ì†Œì¤‘í•œ í”¼ë“œë°± ê°ì‚¬í•©ë‹ˆë‹¤! ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        # í”¼ë“œë°± ì €ì¥ í›„ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
                        del st.session_state['last_input']
                        del st.session_state['pred_class']
                        del st.session_state['score']
                        # st.experimental_rerun() # í•„ìš”ì‹œ í™”ë©´ ìƒˆë¡œê³ ì¹¨
    else:
        st.error("ì‹¤ì‹œê°„ ë¶„ì„ì— í•„ìš”í•œ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
