{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64c8651-eb85-41d2-b1f2-7aa1c53ff071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1000/1000 [==============================] - 26s 19ms/step - loss: 0.3727 - accuracy: 0.8763 - val_loss: 0.2152 - val_accuracy: 0.9347\n",
      "Epoch 2/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1716 - accuracy: 0.9468 - val_loss: 0.1858 - val_accuracy: 0.9468\n",
      "Epoch 3/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1250 - accuracy: 0.9616 - val_loss: 0.1847 - val_accuracy: 0.9460\n",
      "Epoch 4/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0927 - accuracy: 0.9700 - val_loss: 0.2138 - val_accuracy: 0.9426\n",
      "Epoch 5/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0713 - accuracy: 0.9778 - val_loss: 0.2116 - val_accuracy: 0.9441\n",
      "Epoch 6/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0497 - accuracy: 0.9843 - val_loss: 0.2315 - val_accuracy: 0.9432\n",
      "Epoch 7/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0369 - accuracy: 0.9890 - val_loss: 0.2423 - val_accuracy: 0.9443\n",
      "Epoch 8/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0266 - accuracy: 0.9922 - val_loss: 0.3061 - val_accuracy: 0.9398\n",
      "Epoch 9/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.3180 - val_accuracy: 0.9385\n",
      "Epoch 10/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.3004 - val_accuracy: 0.9413\n",
      "Epoch 11/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.3497 - val_accuracy: 0.9378\n",
      "Epoch 12/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.3598 - val_accuracy: 0.9381\n",
      "Epoch 13/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.3467 - val_accuracy: 0.9420\n",
      "Epoch 14/200\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.3976 - val_accuracy: 0.9418\n",
      "Epoch 15/200\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.3545 - val_accuracy: 0.9391\n",
      "Epoch 16/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.3774 - val_accuracy: 0.9435\n",
      "Epoch 17/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.3884 - val_accuracy: 0.9393\n",
      "Epoch 18/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4447 - val_accuracy: 0.9376\n",
      "Epoch 19/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.4476 - val_accuracy: 0.9366\n",
      "Epoch 20/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.4640 - val_accuracy: 0.9207\n",
      "Epoch 21/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4611 - val_accuracy: 0.9423\n",
      "Epoch 22/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.4898 - val_accuracy: 0.9402\n",
      "Epoch 23/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.5713 - val_accuracy: 0.9368\n",
      "Epoch 24/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.4751 - val_accuracy: 0.9387\n",
      "Epoch 25/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.4746 - val_accuracy: 0.9367\n",
      "Epoch 26/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4910 - val_accuracy: 0.9403\n",
      "Epoch 27/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4774 - val_accuracy: 0.9407\n",
      "Epoch 28/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.4933 - val_accuracy: 0.9380\n",
      "Epoch 29/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.4687 - val_accuracy: 0.9402\n",
      "Epoch 30/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.4912 - val_accuracy: 0.9397\n",
      "Epoch 31/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.4799 - val_accuracy: 0.9388\n",
      "Epoch 32/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4763 - val_accuracy: 0.9372\n",
      "Epoch 33/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.5340 - val_accuracy: 0.9408\n",
      "Epoch 34/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 2.9318e-04 - accuracy: 1.0000 - val_loss: 0.5774 - val_accuracy: 0.9391\n",
      "Epoch 35/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 9.2900e-04 - accuracy: 0.9997 - val_loss: 0.5598 - val_accuracy: 0.9407\n",
      "Epoch 36/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.5693 - val_accuracy: 0.9395\n",
      "Epoch 37/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.5294 - val_accuracy: 0.9351\n",
      "Epoch 38/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.5800 - val_accuracy: 0.9365\n",
      "Epoch 39/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 5.1804e-04 - accuracy: 0.9998 - val_loss: 0.5965 - val_accuracy: 0.9345\n",
      "Epoch 40/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.6172 - val_accuracy: 0.9385\n",
      "Epoch 41/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 9.9356e-04 - accuracy: 0.9998 - val_loss: 0.5569 - val_accuracy: 0.9400\n",
      "Epoch 42/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 6.4205e-04 - accuracy: 0.9998 - val_loss: 0.5853 - val_accuracy: 0.9386\n",
      "Epoch 43/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 2.8955e-04 - accuracy: 0.9998 - val_loss: 0.6487 - val_accuracy: 0.9301\n",
      "Epoch 44/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.6011 - val_accuracy: 0.9362\n",
      "Epoch 45/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.5796 - val_accuracy: 0.9386\n",
      "Epoch 46/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.5579 - val_accuracy: 0.9386\n",
      "Epoch 47/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.5547 - val_accuracy: 0.9410\n",
      "Epoch 48/200\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.5780 - val_accuracy: 0.9380\n",
      "Epoch 49/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 9.0685e-04 - accuracy: 0.9997 - val_loss: 0.5943 - val_accuracy: 0.9368\n",
      "Epoch 50/200\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 4.6605e-04 - accuracy: 0.9999 - val_loss: 0.6044 - val_accuracy: 0.9371\n",
      "Epoch 51/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 9.6016e-04 - accuracy: 0.9997 - val_loss: 0.6024 - val_accuracy: 0.9366\n",
      "Epoch 52/200\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 1.5890e-04 - accuracy: 0.9999 - val_loss: 0.6299 - val_accuracy: 0.9376\n",
      "Epoch 53/200\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 4.2174e-04 - accuracy: 0.9999 - val_loss: 0.6445 - val_accuracy: 0.9368\n",
      "Epoch 54/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 3.0146e-04 - accuracy: 0.9998 - val_loss: 0.6449 - val_accuracy: 0.9392\n",
      "Epoch 55/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.5523 - val_accuracy: 0.9403\n",
      "Epoch 56/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 8.6259e-04 - accuracy: 0.9998 - val_loss: 0.5989 - val_accuracy: 0.9402\n",
      "Epoch 57/200\n",
      "1000/1000 [==============================] - 19s 18ms/step - loss: 1.5524e-04 - accuracy: 0.9999 - val_loss: 0.6170 - val_accuracy: 0.9397\n",
      "Epoch 58/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 7.0508e-05 - accuracy: 1.0000 - val_loss: 0.6561 - val_accuracy: 0.9386\n",
      "Epoch 59/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.3322e-04 - accuracy: 0.9999 - val_loss: 0.6688 - val_accuracy: 0.9396\n",
      "Epoch 60/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 5.7157e-04 - accuracy: 0.9997 - val_loss: 0.6281 - val_accuracy: 0.9360\n",
      "Epoch 61/200\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.6493 - val_accuracy: 0.9265\n",
      "Epoch 62/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.6232 - val_accuracy: 0.9397\n",
      "Epoch 63/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 7.4775e-04 - accuracy: 0.9997 - val_loss: 0.6516 - val_accuracy: 0.9358\n",
      "Epoch 64/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.3396e-04 - accuracy: 0.9999 - val_loss: 0.6533 - val_accuracy: 0.9367\n",
      "Epoch 65/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.4975e-04 - accuracy: 0.9999 - val_loss: 0.6753 - val_accuracy: 0.9375\n",
      "Epoch 66/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.4092e-04 - accuracy: 0.9999 - val_loss: 0.7011 - val_accuracy: 0.9396\n",
      "Epoch 67/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.4626e-04 - accuracy: 0.9999 - val_loss: 0.7192 - val_accuracy: 0.9377\n",
      "Epoch 68/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.6188e-04 - accuracy: 0.9999 - val_loss: 0.7386 - val_accuracy: 0.9377\n",
      "Epoch 69/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.7486e-04 - accuracy: 0.9999 - val_loss: 0.7795 - val_accuracy: 0.9371\n",
      "Epoch 70/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.1773e-04 - accuracy: 0.9999 - val_loss: 0.8133 - val_accuracy: 0.9366\n",
      "Epoch 71/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.1971e-04 - accuracy: 0.9999 - val_loss: 0.8322 - val_accuracy: 0.9368\n",
      "Epoch 72/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.0415e-04 - accuracy: 1.0000 - val_loss: 0.8511 - val_accuracy: 0.9377\n",
      "Epoch 73/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.7382 - val_accuracy: 0.9351\n",
      "Epoch 74/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.7973 - val_accuracy: 0.9393\n",
      "Epoch 75/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 4.1552e-04 - accuracy: 0.9998 - val_loss: 0.8252 - val_accuracy: 0.9311\n",
      "Epoch 76/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.6738 - val_accuracy: 0.9365\n",
      "Epoch 77/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.6987 - val_accuracy: 0.9322\n",
      "Epoch 78/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.7408 - val_accuracy: 0.9336\n",
      "Epoch 79/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.7708 - val_accuracy: 0.9308\n",
      "Epoch 80/200\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 2.5113e-04 - accuracy: 0.9999 - val_loss: 0.7941 - val_accuracy: 0.9305\n",
      "Epoch 81/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.5141e-04 - accuracy: 0.9999 - val_loss: 0.8006 - val_accuracy: 0.9318\n",
      "Epoch 82/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.5457e-04 - accuracy: 1.0000 - val_loss: 0.8271 - val_accuracy: 0.9327\n",
      "Epoch 83/200\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 2.3550e-04 - accuracy: 0.9999 - val_loss: 0.8475 - val_accuracy: 0.9337\n",
      "Epoch 84/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 3.1281e-04 - accuracy: 0.9999 - val_loss: 0.8667 - val_accuracy: 0.9300\n",
      "Epoch 85/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.8226 - val_accuracy: 0.9321\n",
      "Epoch 86/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.7707 - val_accuracy: 0.9385\n",
      "Epoch 87/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.7565e-04 - accuracy: 0.9998 - val_loss: 0.7931 - val_accuracy: 0.9350\n",
      "Epoch 88/200\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 2.1332e-04 - accuracy: 0.9999 - val_loss: 0.8204 - val_accuracy: 0.9350\n",
      "Epoch 89/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 5.9624e-04 - accuracy: 0.9998 - val_loss: 0.7837 - val_accuracy: 0.9345\n",
      "Epoch 90/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.4159e-04 - accuracy: 0.9999 - val_loss: 0.7861 - val_accuracy: 0.9346\n",
      "Epoch 91/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.7775e-04 - accuracy: 0.9999 - val_loss: 0.8009 - val_accuracy: 0.9368\n",
      "Epoch 92/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 4.4818e-04 - accuracy: 0.9998 - val_loss: 0.8264 - val_accuracy: 0.9376\n",
      "Epoch 93/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.1771e-04 - accuracy: 1.0000 - val_loss: 0.8537 - val_accuracy: 0.9366\n",
      "Epoch 94/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.8731 - val_accuracy: 0.9335\n",
      "Epoch 95/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.8707 - val_accuracy: 0.9337\n",
      "Epoch 96/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 4.2364e-04 - accuracy: 0.9999 - val_loss: 0.8461 - val_accuracy: 0.9353\n",
      "Epoch 97/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.9069e-04 - accuracy: 0.9999 - val_loss: 0.8500 - val_accuracy: 0.9360\n",
      "Epoch 98/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.3761e-04 - accuracy: 0.9999 - val_loss: 0.8740 - val_accuracy: 0.9368\n",
      "Epoch 99/200\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 1.1395e-04 - accuracy: 0.9999 - val_loss: 0.8963 - val_accuracy: 0.9372\n",
      "Epoch 100/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.8064 - val_accuracy: 0.9347\n",
      "Epoch 101/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.7828 - val_accuracy: 0.9365\n",
      "Epoch 102/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.2659e-04 - accuracy: 1.0000 - val_loss: 0.8097 - val_accuracy: 0.9363\n",
      "Epoch 103/200\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 2.3913e-04 - accuracy: 0.9999 - val_loss: 0.8607 - val_accuracy: 0.9346\n",
      "Epoch 104/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 5.5063e-04 - accuracy: 0.9998 - val_loss: 0.8617 - val_accuracy: 0.9362\n",
      "Epoch 105/200\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 7.9257e-04 - accuracy: 0.9997 - val_loss: 0.8141 - val_accuracy: 0.9358\n",
      "Epoch 106/200\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 5.1587e-04 - accuracy: 0.9999 - val_loss: 0.7888 - val_accuracy: 0.9375\n",
      "Epoch 107/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.1567e-04 - accuracy: 1.0000 - val_loss: 0.8152 - val_accuracy: 0.9380\n",
      "Epoch 108/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.2096e-04 - accuracy: 0.9999 - val_loss: 0.8312 - val_accuracy: 0.9385\n",
      "Epoch 109/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.1399e-04 - accuracy: 0.9999 - val_loss: 0.8639 - val_accuracy: 0.9381\n",
      "Epoch 110/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.2297e-04 - accuracy: 0.9999 - val_loss: 0.8836 - val_accuracy: 0.9378\n",
      "Epoch 111/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.2971e-04 - accuracy: 0.9999 - val_loss: 0.9024 - val_accuracy: 0.9390\n",
      "Epoch 112/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.3300e-04 - accuracy: 0.9999 - val_loss: 0.9255 - val_accuracy: 0.9375\n",
      "Epoch 113/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.1915e-04 - accuracy: 0.9998 - val_loss: 0.9457 - val_accuracy: 0.9326\n",
      "Epoch 114/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.7782 - val_accuracy: 0.9330\n",
      "Epoch 115/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.7416 - val_accuracy: 0.9336\n",
      "Epoch 116/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.9690e-04 - accuracy: 0.9999 - val_loss: 0.7546 - val_accuracy: 0.9392\n",
      "Epoch 117/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 4.3268e-04 - accuracy: 0.9998 - val_loss: 0.8015 - val_accuracy: 0.9367\n",
      "Epoch 118/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.5096e-04 - accuracy: 0.9998 - val_loss: 0.7915 - val_accuracy: 0.9365\n",
      "Epoch 119/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.2126e-04 - accuracy: 0.9999 - val_loss: 0.8280 - val_accuracy: 0.9353\n",
      "Epoch 120/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.0508e-04 - accuracy: 0.9999 - val_loss: 0.8839 - val_accuracy: 0.9265\n",
      "Epoch 121/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 3.3528e-04 - accuracy: 0.9998 - val_loss: 0.8281 - val_accuracy: 0.9375\n",
      "Epoch 122/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.8063 - val_accuracy: 0.9342\n",
      "Epoch 123/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.4272e-04 - accuracy: 0.9999 - val_loss: 0.8425 - val_accuracy: 0.9355\n",
      "Epoch 124/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.0473e-04 - accuracy: 1.0000 - val_loss: 0.8786 - val_accuracy: 0.9366\n",
      "Epoch 125/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.2463e-04 - accuracy: 0.9999 - val_loss: 0.9098 - val_accuracy: 0.9362\n",
      "Epoch 126/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.2028e-04 - accuracy: 0.9999 - val_loss: 0.9040 - val_accuracy: 0.9382\n",
      "Epoch 127/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 8.4417e-04 - accuracy: 0.9997 - val_loss: 0.8148 - val_accuracy: 0.9375\n",
      "Epoch 128/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.3748e-04 - accuracy: 0.9999 - val_loss: 0.8336 - val_accuracy: 0.9373\n",
      "Epoch 129/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 9.4208e-05 - accuracy: 0.9999 - val_loss: 0.8471 - val_accuracy: 0.9378\n",
      "Epoch 130/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.0607e-04 - accuracy: 0.9999 - val_loss: 0.8234 - val_accuracy: 0.9403\n",
      "Epoch 131/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.4364e-04 - accuracy: 0.9999 - val_loss: 0.8308 - val_accuracy: 0.9396\n",
      "Epoch 132/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.7711 - val_accuracy: 0.9407\n",
      "Epoch 133/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.7815 - val_accuracy: 0.9405\n",
      "Epoch 134/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.7988 - val_accuracy: 0.9410\n",
      "Epoch 135/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.7833 - val_accuracy: 0.9391\n",
      "Epoch 136/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 5.4918e-04 - accuracy: 0.9998 - val_loss: 0.8428 - val_accuracy: 0.9377\n",
      "Epoch 137/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.2300e-04 - accuracy: 0.9999 - val_loss: 0.8371 - val_accuracy: 0.9391\n",
      "Epoch 138/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.0710e-04 - accuracy: 0.9999 - val_loss: 0.8607 - val_accuracy: 0.9385\n",
      "Epoch 139/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 9.8728e-05 - accuracy: 0.9999 - val_loss: 0.8761 - val_accuracy: 0.9383\n",
      "Epoch 140/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.2533e-04 - accuracy: 0.9999 - val_loss: 0.8940 - val_accuracy: 0.9386\n",
      "Epoch 141/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 6.9521e-05 - accuracy: 1.0000 - val_loss: 0.8924 - val_accuracy: 0.9390\n",
      "Epoch 142/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 6.4365e-05 - accuracy: 1.0000 - val_loss: 0.9097 - val_accuracy: 0.9425\n",
      "Epoch 143/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.8304 - val_accuracy: 0.9362\n",
      "Epoch 144/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 3.4660e-04 - accuracy: 0.9998 - val_loss: 0.8467 - val_accuracy: 0.9373\n",
      "Epoch 145/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.6589e-04 - accuracy: 0.9999 - val_loss: 0.8227 - val_accuracy: 0.9392\n",
      "Epoch 146/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.1876e-04 - accuracy: 1.0000 - val_loss: 0.8443 - val_accuracy: 0.9377\n",
      "Epoch 147/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.1112e-04 - accuracy: 0.9999 - val_loss: 0.8618 - val_accuracy: 0.9386\n",
      "Epoch 148/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.1129e-04 - accuracy: 0.9999 - val_loss: 0.8670 - val_accuracy: 0.9398\n",
      "Epoch 149/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 2.2422e-04 - accuracy: 0.9998 - val_loss: 0.9110 - val_accuracy: 0.9370\n",
      "Epoch 150/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 9.0336e-04 - accuracy: 0.9997 - val_loss: 0.8423 - val_accuracy: 0.9335\n",
      "Epoch 151/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 3.8174e-04 - accuracy: 0.9998 - val_loss: 0.8500 - val_accuracy: 0.9351\n",
      "Epoch 152/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.3527e-04 - accuracy: 0.9999 - val_loss: 0.9008 - val_accuracy: 0.9272\n",
      "Epoch 153/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 4.9619e-04 - accuracy: 0.9998 - val_loss: 0.8695 - val_accuracy: 0.9350\n",
      "Epoch 154/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.0827e-04 - accuracy: 0.9999 - val_loss: 0.9172 - val_accuracy: 0.9350\n",
      "Epoch 155/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.0322e-04 - accuracy: 0.9999 - val_loss: 0.9278 - val_accuracy: 0.9350\n",
      "Epoch 156/200\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 2.2273e-04 - accuracy: 0.9999 - val_loss: 0.9271 - val_accuracy: 0.9350\n",
      "Epoch 157/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 8.3968e-05 - accuracy: 0.9999 - val_loss: 0.9469 - val_accuracy: 0.9363\n",
      "Epoch 158/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.8843 - val_accuracy: 0.9366\n",
      "Epoch 159/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.2453e-04 - accuracy: 0.9999 - val_loss: 0.9159 - val_accuracy: 0.9362\n",
      "Epoch 160/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.2150e-04 - accuracy: 0.9999 - val_loss: 0.9466 - val_accuracy: 0.9363\n",
      "Epoch 161/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.1839e-04 - accuracy: 0.9999 - val_loss: 0.9913 - val_accuracy: 0.9362\n",
      "Epoch 162/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.1040e-04 - accuracy: 0.9999 - val_loss: 1.0150 - val_accuracy: 0.9362\n",
      "Epoch 163/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.2603e-04 - accuracy: 0.9999 - val_loss: 1.0321 - val_accuracy: 0.9403\n",
      "Epoch 164/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.0442e-04 - accuracy: 0.9999 - val_loss: 1.0344 - val_accuracy: 0.9366\n",
      "Epoch 165/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 6.2049e-05 - accuracy: 1.0000 - val_loss: 1.0524 - val_accuracy: 0.9347\n",
      "Epoch 166/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.1173e-04 - accuracy: 0.9999 - val_loss: 1.0559 - val_accuracy: 0.9363\n",
      "Epoch 167/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.4714e-04 - accuracy: 0.9999 - val_loss: 1.0657 - val_accuracy: 0.9358\n",
      "Epoch 168/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.9627 - val_accuracy: 0.9372\n",
      "Epoch 169/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.9359 - val_accuracy: 0.9393\n",
      "Epoch 170/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.1945e-04 - accuracy: 0.9999 - val_loss: 0.9405 - val_accuracy: 0.9373\n",
      "Epoch 171/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 9.6871e-05 - accuracy: 0.9999 - val_loss: 0.9474 - val_accuracy: 0.9405\n",
      "Epoch 172/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.0015e-04 - accuracy: 1.0000 - val_loss: 0.9705 - val_accuracy: 0.9367\n",
      "Epoch 173/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.3326e-04 - accuracy: 0.9999 - val_loss: 0.9905 - val_accuracy: 0.9376\n",
      "Epoch 174/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.1827e-04 - accuracy: 0.9999 - val_loss: 0.9969 - val_accuracy: 0.9377\n",
      "Epoch 175/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 9.3434e-05 - accuracy: 0.9999 - val_loss: 1.0012 - val_accuracy: 0.9390\n",
      "Epoch 176/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 1.0049 - val_accuracy: 0.9390\n",
      "Epoch 177/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 4.0289e-04 - accuracy: 0.9999 - val_loss: 0.9261 - val_accuracy: 0.9357\n",
      "Epoch 178/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.1697e-04 - accuracy: 0.9999 - val_loss: 0.9386 - val_accuracy: 0.9375\n",
      "Epoch 179/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.1171e-04 - accuracy: 0.9999 - val_loss: 0.9798 - val_accuracy: 0.9373\n",
      "Epoch 180/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.0364e-04 - accuracy: 0.9999 - val_loss: 1.0128 - val_accuracy: 0.9383\n",
      "Epoch 181/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.7417e-04 - accuracy: 0.9999 - val_loss: 1.0104 - val_accuracy: 0.9382\n",
      "Epoch 182/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.3408e-04 - accuracy: 0.9999 - val_loss: 1.0336 - val_accuracy: 0.9370\n",
      "Epoch 183/200\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 9.0627e-05 - accuracy: 1.0000 - val_loss: 1.0630 - val_accuracy: 0.9372\n",
      "Epoch 184/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.2142e-04 - accuracy: 0.9999 - val_loss: 1.0938 - val_accuracy: 0.9388\n",
      "Epoch 185/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.2476e-04 - accuracy: 0.9999 - val_loss: 1.1005 - val_accuracy: 0.9365\n",
      "Epoch 186/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 1.0357 - val_accuracy: 0.9383\n",
      "Epoch 187/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 9.8976e-04 - accuracy: 0.9997 - val_loss: 1.0801 - val_accuracy: 0.9371\n",
      "Epoch 188/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.9919 - val_accuracy: 0.9352\n",
      "Epoch 189/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.6262e-04 - accuracy: 0.9999 - val_loss: 1.0314 - val_accuracy: 0.9362\n",
      "Epoch 190/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.2831e-04 - accuracy: 0.9999 - val_loss: 1.0411 - val_accuracy: 0.9375\n",
      "Epoch 191/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.1908e-04 - accuracy: 0.9999 - val_loss: 1.0449 - val_accuracy: 0.9372\n",
      "Epoch 192/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.2687e-04 - accuracy: 0.9999 - val_loss: 1.0475 - val_accuracy: 0.9378\n",
      "Epoch 193/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.0697e-04 - accuracy: 0.9999 - val_loss: 1.0574 - val_accuracy: 0.9376\n",
      "Epoch 194/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.4894e-04 - accuracy: 0.9999 - val_loss: 1.0685 - val_accuracy: 0.9372\n",
      "Epoch 195/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.9531 - val_accuracy: 0.9340\n",
      "Epoch 196/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 5.8769e-04 - accuracy: 0.9998 - val_loss: 0.9252 - val_accuracy: 0.9345\n",
      "Epoch 197/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.8838 - val_accuracy: 0.9348\n",
      "Epoch 198/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 3.6056e-04 - accuracy: 0.9999 - val_loss: 0.8866 - val_accuracy: 0.9361\n",
      "Epoch 199/200\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.2209e-04 - accuracy: 0.9999 - val_loss: 0.9132 - val_accuracy: 0.9345\n",
      "Epoch 200/200\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.3708e-04 - accuracy: 0.9999 - val_loss: 0.9180 - val_accuracy: 0.9351\n",
      "1250/1250 [==============================] - 9s 7ms/step\n",
      "                                   제목  \\\n",
      "0           [아크(불독)]야누스사냥 화장실갈때 팁있나요?   \n",
      "1          [루미너스]루미너스 8.3 - 3종 챌린지 참여   \n",
      "2           [아크(썬콜)]도원경 사냥터 공유 가능할까요?   \n",
      "3      [루미너스]루미 시작하려는 메린이인데 질문 가능할까요?   \n",
      "4                  [비숍]유챔 세렌 58473클리어   \n",
      "...                               ...   \n",
      "39969       [데몬슬레이어]왜 내가 가는직업마다 ㅈ박는거지   \n",
      "39970         [블래스터]난 이대로는 안 들어올 것 같아   \n",
      "39971       [아란]본섭 때 리레, 웨폰 너프폭 하향 기원   \n",
      "39972                  [아델]컨티가 더좋나본데?   \n",
      "39973        [아델]아니 근데 와중에 임레 딜은 또 깎네   \n",
      "\n",
      "                                                      본문 label pred  \n",
      "0      보통2젠까진 키보드 안눌러도 잡히는거같은데전 캐릭은 오리진 누르고 가면 30초 가만...    중립   중립  \n",
      "1      (3) 루미너스 허수아비 8.3 챌린지 도전 - YouTube긴장을 했는지 평딜 중...    중립   중립  \n",
      "2      안녕하세요 그동안 골목1에서만 사냥했는데 이번에 해방도 하고 아르테리아도 가게돼서 ...    긍정   긍정  \n",
      "3      이번에 친구랑 시작해서 둘이서 검밑까지 2인격 도전하려고하는데딱 30만원만 스팩에 ...    중립   중립  \n",
      "4      이중보약 막날에 56537로 트라이했다가 실패하고 보약 좀 보충하고 헥사 좀 올려서...    부정   부정  \n",
      "...                                                  ...   ...  ...  \n",
      "39969  처음 듀블시작->김창섭 밸패기다려 드림쇼케때도 마코 ㅈ같이줘서 섀도어자전->자전후 ...    긍정   긍정  \n",
      "39970  해매팡은 뭐 그대로 들어오거나 더 박살 날 것 같은데체급만큼은 진짜 이대로 안 들어...    중립   중립  \n",
      "39971  컨티는 변동 없는데공 100퍼  > 공 80퍼20퍼나 깎는 건 심했잖아15퍼 정도로...    부정   부정  \n",
      "39972                        팡이가 리웨 6렙보다 컨티5렙이 딜 더나온다는데?    긍정   긍정  \n",
      "39973                        임레 마코 들어올 때 지랄좀 했다고 뭔놈의 뒤끝이    중립   중립  \n",
      "\n",
      "[39974 rows x 4 columns]\n",
      "✅ 완료: D:\\_NLPTensorGPU\\SentimentAnalysisProj\\data\\posts_labeled_pred.csv\n"
     ]
    }
   ],
   "source": [
    "# sentiment_analysis.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "\n",
    "    \n",
    "    \n",
    "# 프로젝트 루트 경로\n",
    "BASE_DIR = os.getcwd()\n",
    "LIB_DIR  = os.path.join(BASE_DIR, 'lib')\n",
    "\n",
    "# 1) 불용어 로드 (lib/korean_stopwords.txt)\n",
    "stopwords_path = os.path.join(LIB_DIR, 'korean_stopwords.txt')\n",
    "with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(f.read().splitlines())\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = re.sub(r\"[^가-힣0-9a-zA-Z\\s]\", \" \", str(text))\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "def tokenize(text: str) -> list[str]:\n",
    "    tokens = okt.pos(clean_text(text), norm=True, stem=True)\n",
    "    return [\n",
    "        w for w, p in tokens\n",
    "        if p in ('Noun','Verb','Adjective') and w not in stopwords\n",
    "    ]\n",
    "\n",
    "def auto_label(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    키워드 기반 간단 레이블러.\n",
    "    긍정 키워드 많으면 '긍정', 부정 키워드 많으면 '부정', 아니면 '중립'\n",
    "    \"\"\"\n",
    "    pos = ['좋','행복','재밌','최고','감동','훌륭','만족','버프','상향',\n",
    "           '쎔','강함','상위','최상위','신이다','고트','신창섭','떡상','부활',\n",
    "          '득템']\n",
    "    neg = ['별로','싫','안좋','짜증','역겹','불편','실패','누워','버려',\n",
    "           '눈물','열받','너프','접어','떡락','븅','쓰레기','씨발','하향',\n",
    "           '누워','무덤','약한','약함','우울','손해','접을','접어','접게',\n",
    "           '사망','허수딸','하위','조트','최하위','초상집','정상화','등신','병신','●▅▇█▇▆▅▄▇']\n",
    "\n",
    "    texts = (\n",
    "        df.get('제목','').fillna('') + ' ' +\n",
    "        df.get('본문','').fillna('')\n",
    "    ).apply(clean_text)\n",
    "\n",
    "    labels = []\n",
    "    for t in texts:\n",
    "        score = sum(t.count(w) for w in pos) - sum(t.count(w) for w in neg)\n",
    "        if score > 0:\n",
    "            labels.append('긍정')\n",
    "        elif score < 0:\n",
    "            labels.append('부정')\n",
    "        else:\n",
    "            labels.append('중립')\n",
    "    df['label'] = labels\n",
    "    return df\n",
    "\n",
    "def build_tokenizer(texts, num_words=15000):\n",
    "    tok = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
    "    tok.fit_on_texts(texts)\n",
    "    return tok\n",
    "\n",
    "def texts_to_padded_sequences(tok, texts, maxlen=80):\n",
    "    seqs = tok.texts_to_sequences(texts)\n",
    "    return pad_sequences(seqs, maxlen=maxlen, padding='pre', truncating='pre')\n",
    "\n",
    "def read_csv_auto(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    여러 인코딩을 순차 시도해서 CSV를 로드합니다.\n",
    "    \"\"\"\n",
    "    encodings = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']\n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    # 모두 실패 시 예외\n",
    "    raise UnicodeDecodeError(f\"지원하는 인코딩({encodings})으로도 읽을 수 없습니다: {path}\")\n",
    "\n",
    "def main():\n",
    "    # 1) CSV 로드 & 자동 라벨링\n",
    "    data_path = os.path.join(BASE_DIR, 'data', 'posts_label.csv')\n",
    "    df = read_csv_auto(data_path)\n",
    "    df = auto_label(df)\n",
    "\n",
    "    # 2) 전처리 & 토크나이즈\n",
    "    df['text']    = (\n",
    "        df['제목'].fillna('') + ' ' +\n",
    "        df['본문'].fillna('')\n",
    "    ).apply(clean_text)\n",
    "    df['tokens']  = df['text'].apply(tokenize)\n",
    "    df['cleaned'] = df['tokens'].apply(lambda t: \" \".join(t))\n",
    "\n",
    "    # 3) 레이블 인코딩 & 원-핫\n",
    "    le     = LabelEncoder()\n",
    "    y_idx  = le.fit_transform(df['label'])\n",
    "    y      = np.eye(len(le.classes_))[y_idx]\n",
    "\n",
    "    # 4) train/val 분할\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df['cleaned'], y,\n",
    "        test_size=0.2,\n",
    "        stratify=df['label'],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # 5) 토크나이저 생성 & 패딩\n",
    "    tokenizer    = build_tokenizer(X_train)\n",
    "    X_train_pad   = texts_to_padded_sequences(tokenizer, X_train)\n",
    "    X_val_pad     = texts_to_padded_sequences(tokenizer, X_val)\n",
    "\n",
    "    # 6) 모델 정의·학습\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=15000, output_dim=128, input_length=80),\n",
    "        LSTM(128),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(le.classes_), activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train_pad, y_train,\n",
    "        validation_data=(X_val_pad, y_val),\n",
    "        epochs=200, batch_size=32\n",
    "    )\n",
    "\n",
    "    # 7) 전체 데이터에 예측\n",
    "    all_pad = texts_to_padded_sequences(tokenizer, df['cleaned'])\n",
    "    probs   = model.predict(all_pad)\n",
    "    pred    = le.inverse_transform(np.argmax(probs, axis=1))\n",
    "    df['pred'] = pred\n",
    "\n",
    "    # 8) 결과 확인 및 저장\n",
    "    print(df[['제목','본문','label','pred']])\n",
    "    out_path = os.path.join(BASE_DIR, 'data', 'posts_labeled_pred.csv')\n",
    "    df.to_csv(out_path, index=False, encoding='utf-8-sig', errors='replace')\n",
    "    print(f\"✅ 완료: {out_path}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344e6b5d-edfd-4ae6-b9d5-57d33c55d025",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8a7942-ef98-40db-95b9-9dbdf0af8663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-tfgpu",
   "language": "python",
   "name": "nlp-tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
