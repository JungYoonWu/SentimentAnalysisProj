import os
import re
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import numpy as np
import pickle
from konlpy.tag import Okt
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences

# --- ê²½ë¡œ ì„¤ì • ---
BASE_DIR = os.getcwd()
# 1. ëŒ€ì‹œë³´ë“œìš© ì‚¬ì „ ë¶„ì„ ë°ì´í„°
PRED_DATA_PATH = os.path.join(BASE_DIR, 'data', 'posts_labeled_pred.csv')
# 2. ì‹¤ì‹œê°„ ë¶„ì„ìš© ë°°í¬ ëª¨ë¸
PROD_MODEL_DIR = os.path.join(BASE_DIR, 'production_model')
PROD_MODEL_PATH = os.path.join(PROD_MODEL_DIR, 'best_maple_model.h5')
PROD_TOKENIZER_PATH = os.path.join(PROD_MODEL_DIR, 'tokenizer.pkl')
# 3. ë¶ˆìš©ì–´ ì‚¬ì „
STOPWORDS_PATH = os.path.join(BASE_DIR, 'data', 'korean_stopwords.txt')

# --- ë°ì´í„° ë° ëª¨ë¸ ë¡œë”© (ìºì‹±) ---
@st.cache_data
def load_dashboard_data():
    """ëŒ€ì‹œë³´ë“œìš© ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    df = pd.read_csv(PRED_DATA_PATH, encoding='utf-8-sig')
    df['cleaned'] = (df['ì œëª©'].fillna('') + ' ' + df['ë³¸ë¬¸'].fillna('')).apply(lambda x: re.sub(r"[^ê°€-í£0-9a-zA-Z\s]", " ", str(x)))
    df['job'] = df['ì œëª©'].str.extract(r'^\[(.*?)\]').fillna('Unknown')
    return df

@st.cache_resource
def load_prediction_assets():
    """ì‹¤ì‹œê°„ ì˜ˆì¸¡ì— í•„ìš”í•œ ëª¨ë¸, í† í¬ë‚˜ì´ì €, ë¶ˆìš©ì–´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        model = load_model(PROD_MODEL_PATH)
        with open(PROD_TOKENIZER_PATH, 'rb') as f:
            tokenizer = pickle.load(f)
        with open(STOPWORDS_PATH, 'r', encoding='utf-8') as f:
            stopwords = [line.strip() for line in f]
        okt = Okt()
        return model, tokenizer, okt, stopwords
    except FileNotFoundError:
        return None, None, None, []

# ë°ì´í„° ë° ëª¨ë¸ ë¡œë“œ ì‹¤í–‰
df = load_dashboard_data()
model, tokenizer, okt, stopwords = load_prediction_assets()

# --- UI êµ¬ì„± ---
st.set_page_config(layout="wide")
st.title("ğŸ ë©”ì´í”ŒìŠ¤í† ë¦¬ ì§ì—…ë³„ ì—¬ë¡  ëŒ€ì‹œë³´ë“œ & ê°ì„± ë¶„ì„")
st.write("---")

# íƒ­ ìƒì„±
tab1, tab2 = st.tabs(["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ¤– ì‹¤ì‹œê°„ ê°ì„± ë¶„ì„"])

# --- íƒ­ 1: ëŒ€ì‹œë³´ë“œ ---
with tab1:
    col1, col2 = st.columns([1, 3]) # ì‚¬ì´ë“œë°”ì™€ ë©”ì¸ ì˜ì—­ ë¹„ìœ¨

    with col1:
        st.header("ğŸ” í•„í„°")
        boards = ['ì „ì²´'] + sorted(df['ê²Œì‹œíŒ'].unique().tolist())
        sel_board = st.selectbox("ê²Œì‹œíŒ ì„ íƒ", boards)

        if sel_board == 'ì „ì²´':
            jobs = sorted(df['job'].unique().tolist())
        else:
            jobs = sorted(df[df['ê²Œì‹œíŒ'] == sel_board]['job'].unique().tolist())

        sel_all_jobs = st.checkbox("ëª¨ë“  ì§ì—… ì„ íƒ/í•´ì œ", value=True)
        if sel_all_jobs:
            sel_jobs = st.multiselect("ì§ì—… ì„ íƒ", jobs, default=jobs)
        else:
            sel_jobs = st.multiselect("ì§ì—… ì„ íƒ", jobs)

    with col2:
        if sel_jobs:
            df_filtered = df[df['job'].isin(sel_jobs)]
            st.write(f"ì´ **{len(df_filtered)}** ê±´ì˜ ê²Œì‹œê¸€ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

            # 1) ê°ì„± ë¹„ìœ¨ ì°¨íŠ¸
            st.subheader("ê°ì„± ë¶„í¬")
            ratio = df_filtered['pred'].value_counts(normalize=True).reindex(['ê¸ì •','ì¤‘ë¦½','ë¶€ì •'], fill_value=0)
            st.bar_chart(ratio)

            # 2) ì›Œë“œí´ë¼ìš°ë“œ (ë¶ˆìš©ì–´ ì ìš©)
            st.subheader("ì£¼ìš” í‚¤ì›Œë“œ (ì›Œë“œí´ë¼ìš°ë“œ)")
            text = " ".join(df_filtered['cleaned'].tolist())
            font_path = "C:/Windows/Fonts/malgun.ttf" # ìœˆë„ìš° ê¸°ë³¸ í°íŠ¸
            try:
                wc = WordCloud(
                    font_path=font_path, width=800, height=400,
                    background_color='white', stopwords=set(stopwords) # ë¶ˆìš©ì–´ ì ìš©
                ).generate(text)
                fig, ax = plt.subplots(figsize=(10, 5))
                ax.imshow(wc, interpolation='bilinear')
                ax.axis('off')
                st.pyplot(fig)
            except FileNotFoundError:
                st.error(f"í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {font_path}")
            except Exception as e:
                st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        else:
            st.warning("ë¶„ì„í•  ì§ì—…ì„ í•˜ë‚˜ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")

# --- íƒ­ 2: ì‹¤ì‹œê°„ ê°ì„± ë¶„ì„ ---
with tab2:
    st.header("ì‹¤ì‹œê°„ ê°ì„± ë¶„ì„ê¸°")
    st.write("ë©”ì´í”ŒìŠ¤í† ë¦¬ ê´€ë ¨ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ë©´, í•™ìŠµëœ Bi-LSTM ëª¨ë¸ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

    if model:
        user_input = st.text_area("ë¶„ì„í•  ë¬¸ì¥ì„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”:", height=150, key="user_input")
        if st.button("ë¶„ì„ ì‹¤í–‰", key="predict_button"):
            if user_input:
                # ì „ì²˜ë¦¬
                tokenized = [word for word in okt.morphs(user_input, stem=True) if word not in stopwords]
                encoded = tokenizer.texts_to_sequences([tokenized])
                padded = pad_sequences(encoded, maxlen=60) # MAX_LENì€ í•™ìŠµê³¼ ë™ì¼í•˜ê²Œ
                # ì˜ˆì¸¡
                score = model.predict(padded)
                pred_class = np.argmax(score)
                confidence = score[0][pred_class] * 100
                
                # ê²°ê³¼ ì¶œë ¥
                st.subheader("âœ¨ ë¶„ì„ ê²°ê³¼")
                if pred_class == 2: # ê¸ì •
                    st.success(f"ê¸ì •ì ì¸ ì˜ê²¬ì¼ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ({confidence:.2f}%)")
                elif pred_class == 1: # ì¤‘ë¦½
                    st.warning(f"ì¤‘ë¦½ì ì¸ ì˜ê²¬ì¼ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ({confidence:.2f}%)")
                else: # ë¶€ì •
                    st.error(f"ë¶€ì •ì ì¸ ì˜ê²¬ì¼ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ({confidence:.2f}%)")
                
                st.bar_chart({'ê¸ì •': score[0][2], 'ì¤‘ë¦½': score[0][1], 'ë¶€ì •': score[0][0]})
            else:
                st.warning("ë¶„ì„í•  ë¬¸ì¥ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        st.error("ë°°í¬ëœ ë¶„ì„ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìë™í™” íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
