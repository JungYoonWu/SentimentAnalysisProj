# íŒŒì¼ëª…: inference_app.py
import streamlit as st
import os
import pickle
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from konlpy.tag import Okt

# --- ì„¤ì •: ë°°í¬ëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ê²½ë¡œ ---
PROD_MODEL_DIR = './production_model/'
PROD_MODEL_PATH = os.path.join(PROD_MODEL_DIR, 'best_maple_model.h5')
PROD_TOKENIZER_PATH = os.path.join(PROD_MODEL_DIR, 'tokenizer.pkl')
MAX_LEN = 60 # training_pipeline.pyì™€ ë™ì¼í•œ ê°’

# --- ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë”© (ë©”ëª¨ë¦¬ì— ìºì‹±í•˜ì—¬ ì¬ì‹¤í–‰ ì†ë„ í–¥ìƒ) ---
@st.cache_resource
def load_assets():
    """ë°°í¬ëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not os.path.exists(PROD_MODEL_PATH) or not os.path.exists(PROD_TOKENIZER_PATH):
        return None, None, None
    try:
        model = load_model(PROD_MODEL_PATH)
        with open(PROD_TOKENIZER_PATH, 'rb') as f:
            tokenizer = pickle.load(f)
        okt = Okt()
        return model, tokenizer, okt
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None, None

model, tokenizer, okt = load_assets()

# --- Streamlit UI êµ¬ì„± ---
st.set_page_config(page_title="ë©”ì´í”Œ ì¸ë²¤ ê°ì„± ë¶„ì„ê¸°", page_icon="ğŸ")
st.title("ğŸ ë©”ì´í”Œ ì¸ë²¤ ê²Œì‹œê¸€ ê°ì„± ë¶„ì„ê¸°")
st.write("---")
st.write("ë©”ì´í”ŒìŠ¤í† ë¦¬ ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œê¸€ì˜ ê¸ì •/ì¤‘ë¦½/ë¶€ì • ì–´ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

if model is None:
    st.error("ë°°í¬ëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `main.py` íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
else:
    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.text_area("ë¶„ì„í•  ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”:", "ì´ ê²Œì„ ì •ë§ ì¬ë°Œë„¤ìš”! ìºë¦­í„°ë„ ê·€ì—½ê³ ...", height=150)

    if st.button("ê°ì„± ë¶„ì„ ì‹¤í–‰í•˜ê¸°"):
        if user_input:
            # 1. ì „ì²˜ë¦¬ (í˜•íƒœì†Œ ë¶„ì„, ì •ìˆ˜ ì¸ì½”ë”©, íŒ¨ë”©)
            tokenized_sentence = okt.morphs(user_input, stem=True)
            encoded_sentence = tokenizer.texts_to_sequences([tokenized_sentence])
            padded_sentence = pad_sequences(encoded_sentence, maxlen=MAX_LEN)

            # 2. ì˜ˆì¸¡
            score = model.predict(padded_sentence)
            prediction = np.argmax(score)
            confidence = score[0][prediction] * 100

            # 3. ê²°ê³¼ í‘œì‹œ
            st.write("---")
            st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")
            
            if prediction == 0:
                st.error(f"**ë¶€ì •ì ì¸ ì˜ê²¬**ì¼ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ({confidence:.2f}%)")
            elif prediction == 1:
                st.warning(f"**ì¤‘ë¦½ì ì¸ ì˜ê²¬**ì¼ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ({confidence:.2f}%)")
            else: # prediction == 2
                st.success(f"**ê¸ì •ì ì¸ ì˜ê²¬**ì¼ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ({confidence:.2f}%)")

            # ê° í´ë˜ìŠ¤ë³„ í™•ë¥  ì‹œê°í™”
            st.write("ì„¸ë¶€ í™•ë¥ :")
            chart_data = {'ê¸ì •': score[0][2], 'ì¤‘ë¦½': score[0][1], 'ë¶€ì •': score[0][0]}
            st.bar_chart(chart_data)
        else:
            st.warning("ë¶„ì„í•  ë¬¸ì¥ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

